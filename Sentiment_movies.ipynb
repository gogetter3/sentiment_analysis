{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/admin/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 1000 Positive: 1000\n"
     ]
    }
   ],
   "source": [
    "negids = movie_reviews.fileids('neg')\n",
    "posids = movie_reviews.fileids('pos')\n",
    "negfeats = [' '.join(movie_reviews.words(fileids=[f])) for f in negids]\n",
    "posfeats = [' '.join(movie_reviews.words(fileids=[f])) for f in posids]\n",
    "print('Negative:', len(negfeats), 'Positive:', len(posfeats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = negfeats + posfeats\n",
    "y = [0]*1000 + [1]*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard ' s quick movie review damn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>wow ! what a movie . it ' s everything a movie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>richard gere can be a commanding actor , but h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>glory -- starring matthew broderick , denzel w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>steven spielberg ' s second epic film on world...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>truman ( \" true - man \" ) burbank is the perfe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews  y\n",
       "0     plot : two teen couples go to a church party ,...  0\n",
       "1     the happy bastard ' s quick movie review damn ...  0\n",
       "2     it is movies like these that make a jaded movi...  0\n",
       "3     \" quest for camelot \" is warner bros . ' first...  0\n",
       "4     synopsis : a mentally unstable man undergoing ...  0\n",
       "...                                                 ... ..\n",
       "1995  wow ! what a movie . it ' s everything a movie...  1\n",
       "1996  richard gere can be a commanding actor , but h...  1\n",
       "1997  glory -- starring matthew broderick , denzel w...  1\n",
       "1998  steven spielberg ' s second epic film on world...  1\n",
       "1999  truman ( \" true - man \" ) burbank is the perfe...  1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'reviews': reviews, 'y': y})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.25, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описательный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "df['length'] = pd.cut(train.reviews.apply(lambda x: len(x)), bins=[0, 1500, 3000, 4500, float('inf')], \n",
    "       labels=['0-1500', '1500-3000', '3000-4500', '4500+'])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "sns.countplot(x='length', hue='y', data=df);\n",
    "plt.title(\"Распределение длин отзывов\");\n",
    "plt.xlabel(\"Длина отзыва\");\n",
    "plt.ylabel(\"Количество отзывов\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 35317)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "token_matrix = vectorizer.fit_transform(train.reviews)\n",
    "print(token_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1500, 35317)\n"
     ]
    }
   ],
   "source": [
    "transformer = TfidfTransformer()\n",
    "frequency_counts = transformer.fit_transform(token_matrix)\n",
    "print(frequency_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00s</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>05425</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>...</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuehlke</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zukovsky</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zurg</th>\n",
       "      <th>zus</th>\n",
       "      <th>zweibel</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1500 rows × 35317 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  007  00s   03   04   05  05425   10       100  ...  zucker  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.018212  ...     0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...    ...  ...       ...  ...     ...   \n",
       "1495  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.030156  ...     0.0   \n",
       "1496  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "1497  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "1498  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "1499  0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  0.000000  ...     0.0   \n",
       "\n",
       "      zuehlke  zuko  zukovsky  zulu  zurg  zus  zweibel  zwick  zwigoff  \n",
       "0         0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "1         0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "2         0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "3         0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "4         0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "...       ...   ...       ...   ...   ...  ...      ...    ...      ...  \n",
       "1495      0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "1496      0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "1497      0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "1498      0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "1499      0.0   0.0       0.0   0.0   0.0  0.0      0.0    0.0      0.0  \n",
       "\n",
       "[1500 rows x 35317 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(frequency_counts.A, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классы целевой переменной сбалансированы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.reviews.values\n",
    "y = train.y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words =  stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_vectorizer = {\n",
    "    'vectorizer__ngram_range' : [(1, 1), (1, 2), (1, 3), (1, 4)],\n",
    "    'vectorizer__stop_words' : [stop_words, 'english', None],\n",
    "    'vectorizer__max_df' : [0.8, 0.9, 0.95, 1.0],\n",
    "    'vectorizer__min_df' : [1, 10, 20] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pipeline(vectorizer, transformer, classifier):\n",
    "    return Pipeline([\n",
    "            ('vectorizer', vectorizer),\n",
    "            ('transformer', transformer),\n",
    "            ('classifier', classifier)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_estimator(classifier, params_grid, scorer, data, labels):\n",
    "    pipeline = make_pipeline(CountVectorizer(), TfidfTransformer(), classifier)\n",
    "    grid_cv = RandomizedSearchCV(pipeline, params_grid, scoring=scorer, cv=5, random_state=5)\n",
    "    grid_cv.fit(data, labels)\n",
    "    return grid_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линейные классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC - 0.8240000000000001\n",
      "LogisticRegression - 0.796\n",
      "RidgeClassifier - 0.8140000000000001\n",
      "SGDClassifier - 0.8273333333333334\n",
      "CPU times: user 24.1 s, sys: 5.49 s, total: 29.6 s\n",
      "Wall time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key, clf in {'LinearSVC': LinearSVC, 'LogisticRegression': LogisticRegression,\n",
    "                'RidgeClassifier': RidgeClassifier, 'SGDClassifier': SGDClassifier}.items():\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=5)), X, y, cv=5).mean()\n",
    "    print(f\"{key} - {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Настройка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_lsvc = {\n",
    "    'classifier__loss': ['hinge', 'squared_hinge'], \n",
    "    'classifier__tol': [1e-5, 1e-4, 1e-3],\n",
    "    'classifier__max_iter': np.arange(100, 500, 100),\n",
    "    'classifier__C': np.arange(0.1, 2, 0.2)\n",
    "}\n",
    "\n",
    "params_grid_lr = {\n",
    "    \n",
    "    'classifier__max_iter': np.arange(50, 600, 100),\n",
    "    'classifier__solver': ['lbfgs', 'liblinear', 'sag'],\n",
    "    'classifier__C': np.arange(0.1, 2, 0.2)\n",
    "}\n",
    "    \n",
    "params_grid_rc = {\n",
    "    'classifier__normalize': [True, False], \n",
    "    'classifier__tol': np.arange(1e-4, 1e-2, 1e-3),\n",
    "    'classifier__solver': ['auto', 'svd', 'lsqr', 'sparse_cg'],\n",
    "    'classifier__alpha': np.arange(0.1, 4, 0.2)\n",
    "}\n",
    "    \n",
    "params_grid_sgdc = {\n",
    "    'classifier__max_iter': np.arange(100, 1000, 100),\n",
    "    'classifier__loss': ['log', 'hinge', 'modified_huber'], \n",
    "    'classifier__tol': np.arange(1e-5, 1e-3, 1e-4),\n",
    "    'classifier__penalty':  ['l1', 'l2']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC:\n",
      "best quality - 0.8453333333333335\n",
      "params - {'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vectorizer__ngram_range': (1, 2), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__tol': 0.0001, 'classifier__max_iter': 400, 'classifier__loss': 'squared_hinge', 'classifier__C': 1.1000000000000003}\n",
      "CPU times: user 1min 28s, sys: 1.4 s, total: 1min 29s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_lsvc = make_estimator(LinearSVC(random_state=5), \n",
    "                                  {**params_grid_vectorizer, **params_grid_lsvc}, 'accuracy', X, y)\n",
    "print(\"LinearSVC:\")\n",
    "print(f\"best quality - {grid_search_lsvc.best_score_}\")\n",
    "print(f\"params - {grid_search_lsvc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "best quality - 0.8320000000000001\n",
      "params - {'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.9, 'classifier__solver': 'sag', 'classifier__max_iter': 50, 'classifier__C': 1.9000000000000004}\n",
      "CPU times: user 2min 42s, sys: 18.6 s, total: 3min\n",
      "Wall time: 1min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_lr = make_estimator(LogisticRegression(random_state=5), \n",
    "                                {**params_grid_vectorizer, **params_grid_lr}, 'accuracy', X, y)\n",
    "print(\"LogisticRegression:\")\n",
    "print(f\"best quality - {grid_search_lr.best_score_}\")\n",
    "print(f\"params - {grid_search_lr.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeClassifier:\n",
      "best quality - 0.8506666666666666\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 4), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__tol': 0.0071, 'classifier__solver': 'sparse_cg', 'classifier__normalize': True, 'classifier__alpha': 3.7000000000000006}\n",
      "CPU times: user 2min 7s, sys: 7.87 s, total: 2min 15s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_rc = make_estimator(RidgeClassifier(random_state=5), \n",
    "                                {**params_grid_vectorizer, **params_grid_rc}, 'accuracy', X, y)\n",
    "print(\"RidgeClassifier:\")\n",
    "print(f\"best quality - {grid_search_rc.best_score_}\")\n",
    "print(f\"params - {grid_search_rc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier:\n",
      "best quality - 0.8393333333333335\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 10, 'vectorizer__max_df': 1.0, 'classifier__tol': 0.0009100000000000001, 'classifier__penalty': 'l2', 'classifier__max_iter': 900, 'classifier__loss': 'hinge'}\n",
      "CPU times: user 2min 9s, sys: 11.7 s, total: 2min 21s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_sgdc = make_estimator(SGDClassifier(random_state=5), \n",
    "                                  {**params_grid_vectorizer, **params_grid_sgdc}, 'accuracy', X, y)\n",
    "print(\"SGDClassifier:\")\n",
    "print(f\"best quality - {grid_search_sgdc.best_score_}\")\n",
    "print(f\"params - {grid_search_sgdc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model - RidgeClassifier\n",
      "best quality - 0.8506666666666666\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 4), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__tol': 0.0071, 'classifier__solver': 'sparse_cg', 'classifier__normalize': True, 'classifier__alpha': 3.7000000000000006}\n"
     ]
    }
   ],
   "source": [
    "results_linear = {\n",
    "                  'LinearSVC': (grid_search_lsvc.best_score_, grid_search_lsvc.best_params_),\n",
    "                  'LogisticRegression': (grid_search_lr.best_score_, grid_search_lr.best_params_),\n",
    "                  'RidgeClassifier': (grid_search_rc.best_score_, grid_search_rc.best_params_),\n",
    "                  'SGDClassifier': (grid_search_sgdc.best_score_, grid_search_sgdc.best_params_)\n",
    "                  }\n",
    "print(f\"best model - {max(results_linear, key=results_linear.get)}\")\n",
    "print(f\"best quality - {max(results_linear.values())[0]}\")\n",
    "print(f\"params - {max(results_linear.values())[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Байесовские классификаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB - 0.7873333333333332\n",
      "CPU times: user 5.22 s, sys: 54.9 ms, total: 5.27 s\n",
      "Wall time: 5.28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key, clf in {'MultinomialNB': MultinomialNB, 'BernoulliNB': BernoulliNB}.items():\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf()), X, y, cv=5).mean()\n",
    "print(f\"{key} - {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Настройка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_bnb = {\n",
    "    'classifier__fit_prior': [True, False],\n",
    "    'classifier__alpha': np.logspace(0, 5, 30)\n",
    "}\n",
    "params_grid_mnb = { \n",
    "    'classifier__fit_prior': [True, False],\n",
    "    'classifier__alpha': np.logspace(0, 5, 30)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB:\n",
      "best quality - 0.8113333333333334\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__fit_prior': False, 'classifier__alpha': 2.2122162910704493}\n",
      "CPU times: user 2min 4s, sys: 2.44 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_bnb = make_estimator(BernoulliNB(), \n",
    "                                {**params_grid_vectorizer, **params_grid_bnb}, 'accuracy', X, y)\n",
    "print(\"BernoulliNB:\")\n",
    "print(f\"best quality - {grid_search_bnb.best_score_}\")\n",
    "print(f\"params - {grid_search_bnb.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB:\n",
      "best quality - 0.8133333333333332\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__fit_prior': False, 'classifier__alpha': 2.2122162910704493}\n",
      "CPU times: user 2min 4s, sys: 2.46 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_mnb = make_estimator(MultinomialNB(), \n",
    "                                {**params_grid_vectorizer, **params_grid_mnb}, 'accuracy', X, y)\n",
    "print(\"MultinomialNB:\")\n",
    "print(f\"best quality - {grid_search_mnb.best_score_}\")\n",
    "print(f\"params - {grid_search_mnb.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model - MultinomialNB\n",
      "best quality - 0.8133333333333332\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 3), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__fit_prior': False, 'classifier__alpha': 2.2122162910704493}\n"
     ]
    }
   ],
   "source": [
    "results_bayes = {'BernoulliNB': (grid_search_bnb.best_score_, grid_search_bnb.best_params_),\n",
    "                 'MultinomialNB': (grid_search_mnb.best_score_, grid_search_mnb.best_params_)\n",
    "                 }\n",
    "print(f\"best model - {max(results_bayes, key=results_bayes.get)}\")\n",
    "print(f\"best quality - {max(results_bayes.values())[0]}\")\n",
    "print(f\"params - {max(results_bayes.values())[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Решающие деревья"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier - 0.6446666666666666\n",
      "GradientBoostingClassifier - 0.7826666666666666\n",
      "RandomForestClassifier - 0.7746666666666667\n",
      "CPU times: user 51.8 s, sys: 239 ms, total: 52 s\n",
      "Wall time: 52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for key, clf in {'DecisionTreeClassifier': DecisionTreeClassifier, 'GradientBoostingClassifier': GradientBoostingClassifier,\n",
    "                 'RandomForestClassifier': RandomForestClassifier}.items():\n",
    "    score = cross_val_score(make_pipeline(CountVectorizer(), TfidfTransformer(), clf(random_state=5)), X, y, cv=5).mean()\n",
    "    print(f\"{key} - {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Настройка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid_dtc = {\n",
    "    'classifier__max_depth': np.arange(1, 20, 3),\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__min_impurity_decrease': np.logspace(-10, -6, 5),\n",
    "    'classifier__min_samples_split': np.arange(2, 6, 1)\n",
    "}\n",
    "params_grid_gbc = {\n",
    "    'classifier__max_depth': [None] + list(np.arange(1, 12, 3)),\n",
    "    'classifier__n_estimators': np.arange(10, 51, 20),\n",
    "    'classifier__subsample': np.arange(0.6, 1, 0.2),\n",
    "    'classifier__min_samples_split': np.arange(2, 7, 2),\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "params_grid_rfc = {\n",
    "    'classifier__min_samples_split': np.arange(2, 6, 1),\n",
    "    'classifier__n_estimators': np.arange(1, 20, 3),\n",
    "    'classifier__min_samples_leaf': [1, 2, 3],\n",
    "    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'classifier__max_depth': [None] + list(np.arange(1, 20, 3)),\n",
    "    'classifier__min_impurity_decrease': np.logspace(-10, -6, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier:\n",
      "best quality - 0.6633333333333333\n",
      "params - {'vectorizer__stop_words': None, 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 20, 'vectorizer__max_df': 0.9, 'classifier__min_samples_split': 3, 'classifier__min_samples_leaf': 3, 'classifier__min_impurity_decrease': 1e-10, 'classifier__max_depth': 7}\n",
      "CPU times: user 1min 21s, sys: 999 ms, total: 1min 22s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_dtc = make_estimator(DecisionTreeClassifier(random_state=5), \n",
    "                                {**params_grid_vectorizer, **params_grid_dtc}, 'accuracy', X, y)\n",
    "print(\"DecisionTreeClassifier:\")\n",
    "print(f\"best quality - {grid_search_dtc.best_score_}\")\n",
    "print(f\"params - {grid_search_dtc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier:\n",
      "best quality - 0.7953333333333333\n",
      "params - {'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vectorizer__ngram_range': (1, 4), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.9, 'classifier__subsample': 0.8, 'classifier__n_estimators': 50, 'classifier__min_samples_split': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 9}\n",
      "CPU times: user 8min 20s, sys: 3.74 s, total: 8min 24s\n",
      "Wall time: 8min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_gbc = make_estimator(GradientBoostingClassifier(random_state=5), \n",
    "                                {**params_grid_vectorizer, **params_grid_gbc}, 'accuracy', X, y)\n",
    "print(\"GradientBoostingClassifier:\")\n",
    "print(f\"best quality - {grid_search_gbc.best_score_}\")\n",
    "print(f\"params - {grid_search_gbc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier:\n",
      "best quality - 0.7346666666666667\n",
      "params - {'vectorizer__stop_words': 'english', 'vectorizer__ngram_range': (1, 1), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.8, 'classifier__n_estimators': 19, 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 3, 'classifier__min_impurity_decrease': 1e-09, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 16}\n",
      "CPU times: user 59.4 s, sys: 1.06 s, total: 1min\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_search_rfc = make_estimator(RandomForestClassifier(random_state=5), \n",
    "                                {**params_grid_vectorizer, **params_grid_rfc}, 'accuracy', X, y)\n",
    "print(\"RandomForestClassifier:\")\n",
    "print(f\"best quality - {grid_search_rfc.best_score_}\")\n",
    "print(f\"params - {grid_search_rfc.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model - GradientBoostingClassifier\n",
      "best quality - 0.7953333333333333\n",
      "params - {'vectorizer__stop_words': ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"], 'vectorizer__ngram_range': (1, 4), 'vectorizer__min_df': 10, 'vectorizer__max_df': 0.9, 'classifier__subsample': 0.8, 'classifier__n_estimators': 50, 'classifier__min_samples_split': 2, 'classifier__max_features': 'sqrt', 'classifier__max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "results_tree = {'DecisionTreeClassifier': (grid_search_dtc.best_score_, grid_search_dtc.best_params_),\n",
    "                'RandomForestClassifier': (grid_search_rfc.best_score_, grid_search_rfc.best_params_),\n",
    "                'GradientBoostingClassifier': (grid_search_gbc.best_score_, grid_search_gbc.best_params_)\n",
    "                }\n",
    "print(f\"best model - {max(results_tree, key=results_tree.get)}\")\n",
    "print(f\"best quality - {max(results_tree.values())[0]}\")\n",
    "print(f\"params - {max(results_tree.values())[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(max_df=0.8, min_df=10, ngram_range=(1, 4))),\n",
       "                ('transformer', TfidfTransformer()),\n",
       "                ('classifier',\n",
       "                 RidgeClassifier(alpha=3.7, normalize=True, random_state=5,\n",
       "                                 solver='sparse_cg', tol=0.0071))])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc = make_pipeline(CountVectorizer(min_df=10, ngram_range=(1, 4), max_df=0.8, stop_words=None),\n",
    "                    TfidfTransformer(),\n",
    "                    RidgeClassifier(tol=0.0071, solver='sparse_cg', normalize=True,\n",
    "                                    alpha=3.7, random_state=5))\n",
    "rc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(rc.predict(test.reviews), test.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(max_df=0.8, min_df=10, ngram_range=(1, 3))),\n",
       "                ('transformer', TfidfTransformer()),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=2.2122162910704493, fit_prior=False))])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = make_pipeline(CountVectorizer(min_df=10, ngram_range=(1, 3), max_df=0.8, stop_words=None),\n",
    "                    TfidfTransformer(),\n",
    "                    MultinomialNB(alpha=2.2122162910704493, fit_prior=False))\n",
    "mnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(mnb.predict(test.reviews), test.y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer',\n",
       "                 CountVectorizer(max_df=0.9, min_df=10, ngram_range=(1, 4),\n",
       "                                 stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                             'our', 'ours', 'ourselves', 'you',\n",
       "                                             \"you're\", \"you've\", \"you'll\",\n",
       "                                             \"you'd\", 'your', 'yours',\n",
       "                                             'yourself', 'yourselves', 'he',\n",
       "                                             'him', 'his', 'himself', 'she',\n",
       "                                             \"she's\", 'her', 'hers', 'herself',\n",
       "                                             'it', \"it's\", 'its', 'itself', ...])),\n",
       "                ('transformer', TfidfTransformer()),\n",
       "                ('classifier',\n",
       "                 GradientBoostingClassifier(max_depth=9, max_features='sqrt',\n",
       "                                            n_estimators=50, subsample=0.8))])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc = make_pipeline(CountVectorizer(min_df=10, ngram_range=(1, 4), max_df=0.9, \n",
    "                                    stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]),\n",
    "                    TfidfTransformer(),\n",
    "                    GradientBoostingClassifier(subsample=0.8, n_estimators=50, min_samples_split=2, max_features='sqrt', max_depth=9))\n",
    "gbc.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(gbc.predict(test.reviews), test.y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
